{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T06:07:13.459650Z",
     "start_time": "2024-11-22T06:07:12.362335Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "# plt.style.use('seaborn-paper')\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "# plt.rcParams['font.family']='Times New Roman,Microsoft YaHei'# 设置字体族，中文为微软雅黑，英文为Times New Roman\n",
    "plt.rcParams['font.sans-serif'] = 'Times New Roman'\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'  # 设置数学公式字体为stix\n",
    "plt.rcParams[\"text.usetex\"] = False\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.patheffects as path_effects"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "2f5256ff37cf17f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T06:07:15.764293Z",
     "start_time": "2024-11-22T06:07:13.548329Z"
    }
   },
   "source": [
    "datajh=pd.read_csv(\"groupedjhS.csv\")\n",
    "datacm=pd.read_csv(\"groupedcmS.csv\")\n",
    "datajhsoa=pd.read_csv(\"groupedjhSOA.csv\")\n",
    "datacmsoa=pd.read_csv(\"groupedcmSOA.csv\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "6602fec820cdfb29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T06:07:16.317487Z",
     "start_time": "2024-11-22T06:07:16.227554Z"
    }
   },
   "source": [
    "#温度影响\n",
    "VOCs = ['Methyl Mercaptan', '1,3-Butadiene', 'Butene', 'Acetone/Butane', 'n-Propanol',\n",
    "        'Dimethyl Sulfide/Ethyl Mercaptan', 'Chloroethane', 'Isoprene', 'Pentene', 'Pentane/Isopentane',\n",
    "        'Dimethylformamide', 'Ethyl Formate', 'Carbon Disulfide/Propyl Mercaptan', 'Benzene', 'Cyclohexene',\n",
    "        'Hexene/Methylcyclopentane', 'n-Hexane/Dimethylbutane', 'Ethyl Sulfide/Butyl Mercaptan', 'Toluene', 'Aniline',\n",
    "        'Dimethyl Disulfide', '1,1-Dichloroethylene', 'Methylcyclohexane', 'n-Heptane', 'Triethylamine',\n",
    "        'n-Propyl Acetate', 'Diethylene Triamine', 'Styrene', 'Xylene/Ethylbenzene', '1,3-Dichloropropene', 'n-Octane',\n",
    "        'n-Butyl Acetate', 'Hexyl Mercaptan', 'Xylenol', 'Trichloroethylene', 'Diethylbenzene', 'Methyl Benzoate',\n",
    "        'Trimethyl Phosphate', 'n-Decanol', 'Dichlorobenzene', 'Diethyl Aniline', 'Undecane', 'Tetrachloroethylene',\n",
    "        'n-Dodecane', 'Dibromomethane', '1,2,4-Trichlorobenzene', 'n-Tridecane', '1,2-Dibromoethane']\n",
    "\n",
    "datajhsoa[\"SOA\"] = 0\n",
    "datajh[\"SOA\"] = 0\n",
    "for i in datajhsoa.columns[(datajhsoa.columns.get_loc(\"0.25um\")):(datajhsoa.columns.get_loc(\"0.30um\"))]:\n",
    "    datajhsoa[\"SOA\"] = datajhsoa[\"SOA\"] + datajhsoa[i]\n",
    "    datajh[\"SOA\"] = datajh[\"SOA\"] + datajh[i]\n",
    "datajhsoa[\"CSOA\"] = 0\n",
    "for i in datajhsoa.columns[(datajhsoa.columns.get_loc(\"C0.25um\")):(datajhsoa.columns.get_loc(\"C0.30um\"))]:\n",
    "    datajhsoa[\"CSOA\"] = datajhsoa[\"CSOA\"] + datajhsoa[i]\n",
    "datacmsoa[\"SOA\"] = 0\n",
    "datacm[\"SOA\"] = 0\n",
    "for i in datacmsoa.columns[(datacmsoa.columns.get_loc(\"0.25um\")):(datacmsoa.columns.get_loc(\"0.30um\"))]:\n",
    "    datacmsoa[\"SOA\"] = datacmsoa[\"SOA\"] + datacmsoa[i]\n",
    "    datacm[\"SOA\"] = datacm[\"SOA\"] + datacm[i]\n",
    "datacmsoa[\"CSOA\"] = 0\n",
    "for i in datacmsoa.columns[(datacmsoa.columns.get_loc(\"C0.25um\")):(datacmsoa.columns.get_loc(\"C0.30um\"))]:\n",
    "    datacmsoa[\"CSOA\"] = datacmsoa[\"CSOA\"] + datacmsoa[i]\n",
    "datajh['place'] = 'JH'\n",
    "datacm['place'] = 'CM'\n",
    "dataall = pd.concat([datajh, datacm], axis=0)\n",
    "dataall.columns = ['Time', 'TVOCs', 'Methyl Mercaptan', '1,3-Butadiene', 'Butene', 'Acetone/Butane', 'n-Propanol',\n",
    "                   'Dimethyl Sulfide/Ethyl Mercaptan', 'Chloroethane', 'Isoprene', 'Pentene', 'Pentane/Isopentane',\n",
    "                   'Dimethylformamide', 'Ethyl Formate', 'Carbon Disulfide/Propyl Mercaptan', 'Benzene', 'Cyclohexene',\n",
    "                   'Hexene/Methylcyclopentane', 'n-Hexane/Dimethylbutane', 'Ethyl Sulfide/Butyl Mercaptan', 'Toluene',\n",
    "                   'Aniline', 'Dimethyl Disulfide', '1,1-Dichloroethylene', 'Methylcyclohexane', 'n-Heptane',\n",
    "                   'Triethylamine', 'n-Propyl Acetate', 'Diethylene Triamine', 'Styrene', 'Xylene/Ethylbenzene',\n",
    "                   '1,3-Dichloropropene', 'n-Octane', 'n-Butyl Acetate', 'Hexyl Mercaptan', 'Xylenol',\n",
    "                   'Trichloroethylene', 'Diethylbenzene', 'Methyl Benzoate', 'Trimethyl Phosphate', 'n-Decanol',\n",
    "                   'Dichlorobenzene', 'Diethyl Aniline', 'Undecane', 'Tetrachloroethylene', 'n-Dodecane',\n",
    "                   'Dibromomethane', '1,2,4-Trichlorobenzene', 'n-Tridecane', '1,2-Dibromoethane', '0.25um', '0.28um',\n",
    "                   '0.30um', '0.35um', '0.40um', '0.45um', '0.50um', '0.58um', '0.65um', '0.70um', '0.80um', '1.00um',\n",
    "                   '1.30um', '1.60um', '2.00um', '2.50um', '3.00um', '3.50um', '4.00um', '5.00um', '6.50um', '7.50um',\n",
    "                   '8.50um', '10.00um', '12.50um', '15.00um', '17.50um', '20.00um', '25.00um', '30.00um', '32.00um',\n",
    "                   'PM10', 'PM2.5', 'PM1', 'SO2', 'NOx', 'NO', 'NO2', 'CO', 'O3', 'NO2.1', 'NegativeOxygenIons',\n",
    "                   'Radiation', 'Temperature', 'Humidity', 'WindSpeed', 'Hour_Min_Sec', 'Hour_Min', 'Hour', 'Month',\n",
    "                   'Day', 'Datetime', 'seconds', 'SOA', 'place']\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ec782e2544fe72f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T15:27:08.866145Z",
     "start_time": "2024-11-11T15:27:08.758557Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import zscore\n",
    "from matplotlib.ticker import FuncFormatter, MaxNLocator\n",
    "import matplotlib.dates as mdates\n",
    "from scipy.stats import t\n",
    "\n",
    "\n",
    "# 定义与均值的关系函数（二次函数）\n",
    "def mean_relation(T, Q0, a, v0):\n",
    "    return Q0 + (a * T**2) / 2 + T * v0\n",
    "\n",
    "# 定义与方差的关系函数（三次函数）\n",
    "def std_dev_relation(T, k, sigma0):\n",
    "    return (k**2 * T**3) / 3 + k * T**2 * sigma0 + T * sigma0**2\n",
    "\n",
    "\n",
    "# 定义去除离群值的函数（使用 Z-score 方法）\n",
    "def remove_outliers(data):\n",
    "    z_scores = zscore(data)\n",
    "    return data[(np.abs(z_scores) < 3)]  # 通常使用 3 作为 Z-score 的阈值\n",
    "    \n",
    "from scipy.spatial import ConvexHull\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "from scipy.stats import norm\n",
    "\n",
    "def compute_area(points):\n",
    "    # 计算点的凸包区域\n",
    "    hull = ConvexHull(points)\n",
    "    polygon = Polygon(points[hull.vertices])\n",
    "    return polygon.area\n",
    "\n",
    "def monte_carlo_r_squared_area(T, mean_params, std_dev_params, real_data, num_simulations=1000):\n",
    "    original_points = np.column_stack((T, real_data))\n",
    "    original_area = compute_area(original_points)\n",
    "\n",
    "    simulation_areas = []\n",
    "    overlap_areas = []\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        simulated_path = norm.rvs(\n",
    "            loc=mean_relation(T, *mean_params),\n",
    "            scale=np.sqrt(std_dev_relation(T, *std_dev_params)),\n",
    "            size=len(T)\n",
    "        )\n",
    "        simulated_points = np.column_stack((T, simulated_path))\n",
    "        sim_area = compute_area(simulated_points)\n",
    "        simulation_areas.append(sim_area)\n",
    "\n",
    "        original_polygon = Polygon(original_points[ConvexHull(original_points).vertices])\n",
    "        simulated_polygon = Polygon(simulated_points[ConvexHull(simulated_points).vertices])\n",
    "        intersection_area = original_polygon.intersection(simulated_polygon).area\n",
    "        overlap_areas.append(intersection_area)\n",
    "    \n",
    "    mean_overlap_area = np.mean(overlap_areas)\n",
    "    mean_simulation_area = np.mean(simulation_areas)\n",
    "\n",
    "    # Calculate R² based on area overlap\n",
    "    r_squared_area = mean_overlap_area / original_area\n",
    "    return min(max(r_squared_area, 0), 1)  # Ensure R² is in [0, 1]\n",
    "\n",
    "# 定义异常值清理函数\n",
    "def clean_data(df, columns, threshold=3):\n",
    "    for col in columns:\n",
    "        df = df[np.abs(zscore(df[col])) < threshold]\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def hour_min_to_float(hour_min_str):\n",
    "    hour, minute = map(int, hour_min_str.split(\":\"))\n",
    "    return hour + minute / 60.0\n",
    "\n",
    "import re\n",
    "def scientific_notation_with_superscript(value, precision=3):\n",
    "    # 如果值为零，直接返回零字符串格式\n",
    "    if value == 0:\n",
    "        return f\"{value:.{precision}f}\"\n",
    "    \n",
    "    # 格式化为科学记数法，并去掉指数部分的前导零\n",
    "    formatted_value = f\"{value:.{precision}e}\"\n",
    "    formatted_value = formatted_value.replace('e+', 'x10^').replace('e-', 'x10^-')\n",
    "    formatted_value = re.sub(r'x10\\^([-+]?)0*(\\d+)', r'x10^\\1\\2', formatted_value)  # 保留负号\n",
    "    \n",
    "    # 将指数部分的数字替换为 Unicode 上标\n",
    "    superscript_map = str.maketrans(\"0123456789-\", \"⁰¹²³⁴⁵⁶⁷⁸⁹⁻\")\n",
    "    match = re.search(r'x10\\^([-+]?\\d+)', formatted_value)\n",
    "    if match:\n",
    "        exponent = match.group(1).translate(superscript_map)\n",
    "        formatted_value = re.sub(r'x10\\^[-+]?\\d+', f'x10{exponent}', formatted_value)\n",
    "         # 如果是 x10⁰ 则移除\n",
    "        if 'x10⁰' in formatted_value:\n",
    "            formatted_value = formatted_value.replace('x10⁰', '')\n",
    "    else:\n",
    "        # 如果没有 x10^，直接返回数值部分\n",
    "        formatted_value = formatted_value.split('x10')[0]\n",
    "         # 如果是 x10⁰ 则移除\n",
    "        if 'x10⁰' in formatted_value:\n",
    "            formatted_value = formatted_value.replace('x10⁰', '')\n",
    "        \n",
    "    return formatted_value\n",
    "\n",
    "from scipy.stats import norm, expon, gamma, lognorm, beta, kstest, shapiro\n",
    "def normal_distribution_fit_and_test(grouped_by_hour):\n",
    "    normality_results = {}\n",
    "    for hour, group in grouped_by_hour:\n",
    "        # Fit normal distribution and get parameters\n",
    "        params = norm.fit(group)\n",
    "        # Perform Shapiro-Wilk test\n",
    "        _, p_value = shapiro(group)\n",
    "        # Check if data is normally distributed based on p-value\n",
    "        is_normal = True if p_value > 0.05 else False\n",
    "        normality_results[hour] = (\n",
    "        params[0], params[1], p_value, is_normal)  # params[0]: mean, params[1]: standard deviation\n",
    "\n",
    "    normality_df = pd.DataFrame(normality_results).T\n",
    "    normality_df.columns = [\"Mean\", \"Standard Deviation\", \"P-Value\", \"Is Normal\"]\n",
    "    normality_df.reset_index(inplace=True)\n",
    "    normality_df.rename(columns={'index': 'Hour'}, inplace=True)\n",
    "\n",
    "    return normality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db519755f0b11fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T15:27:09.365012Z",
     "start_time": "2024-11-11T15:27:09.134830Z"
    }
   },
   "outputs": [],
   "source": [
    "# 从 dataall 中筛选出 JH 和 CM 地点的数据\n",
    "data_jh = dataall[dataall['place'] == 'JH'].copy()\n",
    "data_cm = dataall[dataall['place'] == 'CM'].copy()\n",
    "data=dataall.groupby([\"Hour_Min\"]).mean(numeric_only=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c5b9f62331a858f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T15:27:09.676328Z",
     "start_time": "2024-11-11T15:27:09.646957Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_models_for_location(data_location):\n",
    "    # 计算每小时的均值\n",
    "    datare = data_location.groupby([\"Hour_Min\"]).mean(numeric_only=True).reset_index()\n",
    "    dataj = pd.DataFrame({\n",
    "        \"Time\": pd.to_datetime(datare[\"Hour_Min\"]),\n",
    "        \"T\": datare[\"Temperature\"],\n",
    "        \"hv\": datare[\"Radiation\"],\n",
    "        \"RH\": datare[\"Humidity\"],\n",
    "        \"O3\": datare[\"O3\"],\n",
    "        \"NOx\": datare[\"NOx\"],\n",
    "        \"SO2\": datare[\"SO2\"],\n",
    "        \"SOA\": datare[\"SOA\"],\n",
    "        \"K\": 1,\n",
    "        'Isoprene': datare[\"Isoprene\"]\n",
    "    })\n",
    "\n",
    "    # 计算交互变量\n",
    "    dataj[\"HNO3\"] = dataj[\"RH\"] * dataj[\"NOx\"]\n",
    "    dataj[\"H2SO4\"] = dataj[\"RH\"] * dataj[\"SO2\"]\n",
    "    dataj[\"H2SO403\"] = dataj[\"RH\"] * dataj[\"SO2\"] * dataj[\"O3\"]\n",
    "    dataj[\"HNO3O3\"] = dataj[\"RH\"] * dataj[\"NOx\"] * dataj[\"O3\"]\n",
    "    dataj[\"O3hv\"] = dataj[\"O3\"] * dataj[\"hv\"]\n",
    "\n",
    "    variables_to_regress = [\"HNO3\", \"H2SO4\", \"H2SO403\", \"HNO3O3\", \"O3hv\", \"K\", \"hv\"]\n",
    "\n",
    "    # 模型 1：直接使用观测到的 Isoprene 浓度\n",
    "    dataj[\"BVOCs\"] = datare[\"Isoprene\"]\n",
    "    for var in variables_to_regress:\n",
    "        dataj[var + \"_BVOCs\"] = dataj[var] * dataj[\"Isoprene\"]\n",
    "    \n",
    "\n",
    "    # 模型 2：使用温度拟合 Isoprene 的均值和方差，再以方差为权重拟合 SOA\n",
    "    data_grouped = data_location.groupby([\"Hour_Min\"]).mean(numeric_only=True).reset_index()\n",
    "    data_grouped[\"Concentration\"] = data_grouped[\"Isoprene\"]\n",
    "    grouped_by_hour = data_grouped.groupby('Hour')\n",
    "    normality_df = normal_distribution_fit_and_test(grouped_by_hour[\"Isoprene\"])\n",
    "    normality_df['T'] = data_grouped.groupby('Hour').mean(numeric_only=True)[\"Temperature\"]\n",
    "\n",
    "    # 提取数据\n",
    "    T = normality_df['T'].values\n",
    "    mean_values = normality_df['Mean'].astype(\"float\").values\n",
    "    std_dev_values = normality_df['Standard Deviation'].astype(\"float\").values ** 2\n",
    "\n",
    "    # 去除离群值\n",
    "    mean_values_filtered = remove_outliers(mean_values)\n",
    "    std_dev_values_filtered = remove_outliers(std_dev_values)\n",
    "    T_filtered_mean = T[np.isin(mean_values, mean_values_filtered)]\n",
    "    T_filtered_std_dev = T[np.isin(std_dev_values, std_dev_values_filtered)]\n",
    "\n",
    "    # 拟合模型\n",
    "    params_mean, _ = curve_fit(mean_relation, T_filtered_mean, mean_values_filtered, method='trf', maxfev=10000)\n",
    "    params_std_dev, _ = curve_fit(std_dev_relation, T_filtered_std_dev, std_dev_values_filtered, method='trf')\n",
    "\n",
    "    # 计算 fitted Isoprene 和权重\n",
    "    mean_isoprene = mean_relation(dataj[\"T\"], *params_mean)\n",
    "    std_dev_isoprene = std_dev_relation(dataj[\"T\"], *params_std_dev)\n",
    "    dataj[\"Isoprene_fitted\"] = mean_isoprene\n",
    "    weights = 1 / std_dev_isoprene  # 使用方差的倒数作为权重\n",
    "\n",
    "    for var in variables_to_regress:\n",
    "        dataj[var + \"_BVOCs\"] = dataj[var] * dataj[\"Isoprene_fitted\"]\n",
    "\n",
    "    X2 = dataj[[var + \"_BVOCs\" for var in variables_to_regress]]\n",
    "    Y2 = dataj[\"SOA\"]\n",
    "    model2 = sm.WLS(Y2, X2, weights=weights).fit(cov_type='HC3')\n",
    "\n",
    "\n",
    "    # 输出模型\n",
    "    return model2,params_mean,params_std_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f377a9ccadec2dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T09:09:35.864472Z",
     "start_time": "2024-11-11T09:09:35.850018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12696495955123446"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataall['SOA'].mean()/dataall['PM2.5'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46b5f425b1bc278d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T15:28:00.780845Z",
     "start_time": "2024-11-11T15:28:00.228431Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aa271\\AppData\\Local\\Temp\\ipykernel_26556\\4240856103.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  \"Time\": pd.to_datetime(datare[\"Hour_Min\"]),\n",
      "C:\\Users\\aa271\\AppData\\Local\\Temp\\ipykernel_26556\\4240856103.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  \"Time\": pd.to_datetime(datare[\"Hour_Min\"]),\n"
     ]
    }
   ],
   "source": [
    "# 构建 JH 和 CM 地点的模型\n",
    "modeljh,params_meanjh,params_std_devjh= create_models_for_location(data_jh)\n",
    "modelcm,params_meancm,params_std_devcm=create_models_for_location(data_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adb68ac184bb7b49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:39:43.983940Z",
     "start_time": "2024-11-11T16:39:43.789003Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aa271\\AppData\\Local\\Temp\\ipykernel_26556\\4240856103.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  \"Time\": pd.to_datetime(datare[\"Hour_Min\"]),\n"
     ]
    }
   ],
   "source": [
    "modelall,params_mean,params_std_dev=create_models_for_location(dataall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7219a79b9f18e4ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:18:10.250141Z",
     "start_time": "2024-11-11T16:18:10.089880Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_location=data_jh.copy()\n",
    "# params_mean=params_meanjh\n",
    "# params_std_dev=params_std_devjh\n",
    "# model=modeljh\n",
    "\n",
    "# data_location=data_cm.copy()\n",
    "# params_mean=params_meancm\n",
    "# params_std_dev=params_std_devcm\n",
    "# model=modelcm\n",
    "\n",
    "data_location=dataall.copy()\n",
    "params_mean=params_mean\n",
    "params_std_dev=params_std_dev\n",
    "model=modelall\n",
    "\n",
    "# 计算每小时的均值\n",
    "datare = data_location.groupby([\"Hour_Min\"]).mean(numeric_only=True).reset_index()\n",
    "dataj = pd.DataFrame({\n",
    "    \"Time\": datare[\"Hour_Min\"],\n",
    "    \"T\": datare[\"Temperature\"],\n",
    "    \"hv\": datare[\"Radiation\"],\n",
    "    \"RH\": datare[\"Humidity\"],\n",
    "    \"O3\": datare[\"O3\"],\n",
    "    \"NOx\": datare[\"NOx\"],\n",
    "    \"SO2\": datare[\"SO2\"],\n",
    "    \"SOA\": datare[\"SOA\"],\n",
    "    \"K\": 1,\n",
    "    'Isoprene': datare[\"Isoprene\"]\n",
    "})\n",
    "\n",
    "# 计算交互变量\n",
    "dataj[\"HNO3\"] = dataj[\"RH\"] * dataj[\"NOx\"]\n",
    "dataj[\"H2SO4\"] = dataj[\"RH\"] * dataj[\"SO2\"]\n",
    "dataj[\"H2SO403\"] = dataj[\"RH\"] * dataj[\"SO2\"] * dataj[\"O3\"]\n",
    "dataj[\"HNO3O3\"] = dataj[\"RH\"] * dataj[\"NOx\"] * dataj[\"O3\"]\n",
    "dataj[\"O3hv\"] = dataj[\"O3\"] * dataj[\"hv\"]\n",
    "\n",
    "variables_to_regress = [\"HNO3\", \"H2SO4\", \"H2SO403\", \"HNO3O3\", \"O3hv\", \"K\", \"hv\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de76fd56a22b7517",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:18:12.349747Z",
     "start_time": "2024-11-11T16:18:12.325308Z"
    }
   },
   "outputs": [],
   "source": [
    "dataj[\"Isoprene_fitted\"] = mean_relation(dataj[\"T\"], *params_mean)\n",
    "for var in variables_to_regress:\n",
    "    dataj[var + \"_BVOCs\"] = dataj[var] * dataj[\"Isoprene_fitted\"]\n",
    "\n",
    "X = dataj[[var + \"_BVOCs\" for var in variables_to_regress]]\n",
    "Y = model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19a0632726c56569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:18:40.415686Z",
     "start_time": "2024-11-11T16:18:29.091107Z"
    }
   },
   "outputs": [],
   "source": [
    "# 生成50条随机的温度序列\n",
    "num_simulations = 1000\n",
    "dataset=[]\n",
    "\n",
    "# 生成原始情况的SOA\n",
    "mean_isoprene = mean_relation(dataj[\"T\"], *params_mean)\n",
    "std_dev_isoprene = std_dev_relation(dataj[\"T\"], *params_std_dev)\n",
    "\n",
    "for i in range(num_simulations):\n",
    "    random_BVOCs = np.random.normal(loc=mean_isoprene, scale=std_dev_isoprene, size=dataj.shape[0])\n",
    "    dataj[\"Isoprene_fitted\"] = random_BVOCs\n",
    "    for var in variables_to_regress:\n",
    "        dataj[var + \"_BVOCs\"] = dataj[var] * dataj[\"Isoprene_fitted\"]\n",
    "    \n",
    "    X = dataj[[var + \"_BVOCs\" for var in variables_to_regress]]\n",
    "    Y = model.predict(X)\n",
    "    \n",
    "    temp_data = pd.DataFrame({\n",
    "        \"Time\": dataj[\"Time\"],\n",
    "        \"Temperature\": dataj[\"T\"],\n",
    "        \"BVOCs\": dataj[\"Isoprene_fitted\"],\n",
    "        \"SOA\": Y\n",
    "    })\n",
    "    dataset.append(temp_data)\n",
    "\n",
    "# 生成1.5°C温升情景的SOA\n",
    "mean_isoprene = mean_relation(dataj[\"T\"] + 1.5, *params_mean)\n",
    "std_dev_isoprene = std_dev_relation(dataj[\"T\"] + 1.5, *params_std_dev)\n",
    "\n",
    "for i in range(num_simulations):\n",
    "    random_BVOCs = np.random.normal(loc=mean_isoprene, scale=std_dev_isoprene, size=dataj.shape[0])\n",
    "    dataj[\"Isoprene_fitted\"] = random_BVOCs\n",
    "    for var in variables_to_regress:\n",
    "        dataj[var + \"_BVOCs\"] = dataj[var] * dataj[\"Isoprene_fitted\"]\n",
    "    \n",
    "    X = dataj[[var + \"_BVOCs\" for var in variables_to_regress]]\n",
    "    Y = model.predict(X)\n",
    "    \n",
    "    temp_data = pd.DataFrame({\n",
    "        \"Time\": dataj[\"Time\"],\n",
    "        \"Temperature\": dataj[\"T\"] + 1.5,\n",
    "        \"BVOCs\": dataj[\"Isoprene_fitted\"],\n",
    "        \"SOA\": Y\n",
    "    })\n",
    "    dataset.append(temp_data)\n",
    "\n",
    "# 生成2°C温升情景的SOA\n",
    "mean_isoprene = mean_relation(dataj[\"T\"] + 2, *params_mean)\n",
    "std_dev_isoprene = std_dev_relation(dataj[\"T\"] + 2, *params_std_dev)\n",
    "\n",
    "for i in range(num_simulations):\n",
    "    random_BVOCs = np.random.normal(loc=mean_isoprene, scale=std_dev_isoprene, size=dataj.shape[0])\n",
    "    dataj[\"Isoprene_fitted\"] = random_BVOCs\n",
    "    for var in variables_to_regress:\n",
    "        dataj[var + \"_BVOCs\"] = dataj[var] * dataj[\"Isoprene_fitted\"]\n",
    "    \n",
    "    X = dataj[[var + \"_BVOCs\" for var in variables_to_regress]]\n",
    "    Y = model.predict(X)\n",
    "    \n",
    "    temp_data = pd.DataFrame({\n",
    "        \"Time\": dataj[\"Time\"],\n",
    "        \"Temperature\": dataj[\"T\"] + 2,\n",
    "        \"BVOCs\": dataj[\"Isoprene_fitted\"],\n",
    "        \"SOA\": Y\n",
    "    })\n",
    "    dataset.append(temp_data)\n",
    "\n",
    "# 生成3°C温升情景的SOA\n",
    "mean_isoprene = mean_relation(dataj[\"T\"] + 3, *params_mean)\n",
    "std_dev_isoprene = std_dev_relation(dataj[\"T\"] + 3, *params_std_dev)\n",
    "\n",
    "for i in range(num_simulations):\n",
    "    random_BVOCs = np.random.normal(loc=mean_isoprene, scale=std_dev_isoprene, size=dataj.shape[0])\n",
    "    dataj[\"Isoprene_fitted\"] = random_BVOCs\n",
    "    for var in variables_to_regress:\n",
    "        dataj[var + \"_BVOCs\"] = dataj[var] * dataj[\"Isoprene_fitted\"]\n",
    "    \n",
    "    X = dataj[[var + \"_BVOCs\" for var in variables_to_regress]]\n",
    "    Y = model.predict(X)\n",
    "    \n",
    "    temp_data = pd.DataFrame({\n",
    "        \"Time\": dataj[\"Time\"],\n",
    "        \"Temperature\": dataj[\"T\"] + 3,\n",
    "        \"BVOCs\": dataj[\"Isoprene_fitted\"],\n",
    "        \"SOA\": Y\n",
    "    })\n",
    "    dataset.append(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0af27ec31a51a4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:18:46.565226Z",
     "start_time": "2024-11-11T16:18:40.420466Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 用于存储每个 model 的均值超标和总体超标比例\n",
    "# exceedance_dict = {}\n",
    "# \n",
    "# # 总时间点数量\n",
    "# total_time_points = dataset[0].shape[0]\n",
    "# \n",
    "# # 遍历每个模拟情景数据集并计算超标比例\n",
    "# for data in dataset:\n",
    "#     # 根据温度值判断当前数据的模式\n",
    "#     if data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0]:\n",
    "#         model_label = \"Baseline\"\n",
    "#     elif data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0] + 1.5:\n",
    "#         model_label = \"+1.5°C Warming\"\n",
    "#     elif data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0] + 2:\n",
    "#         model_label = \"+2.0°C Warming\"\n",
    "#     elif data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0] + 3:\n",
    "#         model_label = \"+3.0°C Warming\"\n",
    "#     else:\n",
    "#         continue  # 跳过不匹配任何情景的数据\n",
    "# \n",
    "#     # 初始化 model 的记录\n",
    "#     if model_label not in exceedance_dict:\n",
    "#         exceedance_dict[model_label] = {\"mean_exceedance\": 0, \"total_exceedance\": 0, \"count\": 0, \"exceed_times\": set()}\n",
    "# \n",
    "#     # 计算 mean_exceedance：按 Time 分组计算 SOA 的均值并检查是否超过 5\n",
    "#     mean_exceedance = (data.groupby(\"Time\")[\"SOA\"].mean() > 5).mean() * 100\n",
    "#     \n",
    "#     # 找出该路径中所有超标的时间点\n",
    "#     exceed_times = set(data.loc[data[\"SOA\"] > 5, \"Time\"])\n",
    "# \n",
    "#     # 更新超标时间点集合（集合自动去重）\n",
    "#     exceedance_dict[model_label][\"exceed_times\"].update(exceed_times)\n",
    "# \n",
    "#     # 累加 mean_exceedance\n",
    "#     exceedance_dict[model_label][\"mean_exceedance\"] += mean_exceedance\n",
    "#     exceedance_dict[model_label][\"count\"] += 1\n",
    "# \n",
    "# # 计算每个 model 的平均超标比例和总体超标比例\n",
    "# for model in exceedance_dict:\n",
    "#     # 计算均值超标比例\n",
    "#     exceedance_dict[model][\"mean_exceedance\"] /= exceedance_dict[model][\"count\"]\n",
    "#     # 计算总超标比例\n",
    "#     exceedance_dict[model][\"total_exceedance\"] = len(exceedance_dict[model][\"exceed_times\"]) / total_time_points * 100\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0994564ef15b36c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:18:46.997456Z",
     "start_time": "2024-11-11T16:18:46.768197Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# 初始化字典，用于跟踪每个 model 的采样次数\n",
    "sample_counts = {\"Baseline\": 0, \"+1.5°C Warming\": 0, \"+2.0°C Warming\": 0, \"+3.0°C Warming\": 0}\n",
    "\n",
    "# 遍历每个模拟情景并添加到 combined_data 中，控制每个 model 最多 10 次\n",
    "for data in dataset:\n",
    "    # 根据温度值判断当前数据的模式并添加到新列 'model'\n",
    "    if data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0]:\n",
    "        model_label = \"Baseline\"\n",
    "    elif data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0] + 1.5:\n",
    "        model_label = \"+1.5°C Warming\"\n",
    "    elif data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0] + 2:\n",
    "        model_label = \"+2.0°C Warming\"\n",
    "    elif data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0] + 3:\n",
    "        model_label = \"+3.0°C Warming\"\n",
    "    else:\n",
    "        continue  # 如果不匹配任何情景，跳过当前数据\n",
    "\n",
    "    # 如果当前 model 已经有 10 次采样，则跳过\n",
    "    if sample_counts[model_label] >= 10:\n",
    "        continue\n",
    "\n",
    "    # 设置 model 列，并添加到 combined_data 中\n",
    "    data[\"model\"] = model_label\n",
    "    combined_data = pd.concat([combined_data, data], ignore_index=True)\n",
    "    \n",
    "    # 更新采样次数\n",
    "    sample_counts[model_label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9e260fe00ef36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:56:23.715668Z",
     "start_time": "2024-11-11T17:56:00.312078Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, lines\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.patheffects as path_effects\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "colors = ['#464AA6', '#F2CB05', '#F28A2E', '#BF2633']\n",
    "# 设置图形尺寸\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "gs = fig.add_gridspec(2,2)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax3 = fig.add_subplot(gs[1, :])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 第一张图：SOA密度图 (subplot 1)\n",
    "sns.kdeplot(data=combined_data, x='SOA', hue=\"model\", fill=True, palette=colors,ax=ax1)\n",
    "ax1.set_title(\"\")\n",
    "ax1.set_xlabel(r\"SOA ($\\boldsymbol{μg/m^3}$)\", fontsize=13, weight='bold')\n",
    "ax1.set_ylabel(\"Density\", fontsize=13, weight='bold')\n",
    "ax1.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "# 优化刻度标签的样式\n",
    "ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax1.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.2f}'))  # Y轴格式化显示两位小数\n",
    "ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.2f}'))  # Y轴格式化显示两位小数\n",
    "ax1.legend_.remove()  \n",
    "\n",
    "\n",
    "\n",
    "# 第二张图：SOA路径线条图 (subplot 2)\n",
    "model_label_tex = (\n",
    "    r\"$\\boldsymbol{C(T)} [(\\boldsymbol{k_{O3}}\\boldsymbol{hv} +$\" + \"\\n\" +\n",
    "    r\"$\\boldsymbol{k_{NOx,O3}}[\\boldsymbol{NO3}][\\boldsymbol{RH}] +$\" + \"\\n\" +\n",
    "    r\"$\\boldsymbol{k_{SO2,O3}}[\\boldsymbol{SO2}][\\boldsymbol{RH}]$)$[\\boldsymbol{O3}]$ +\" + \"\\n\" +\n",
    "    r\"$\\boldsymbol{k_{NOx}}[\\boldsymbol{NO3}] [\\boldsymbol{RH}] + $\" + \"\\n\" +\n",
    "    r\"$\\boldsymbol{k_{SO2}}[\\boldsymbol{SO2}][\\boldsymbol{RH}] +$\" + \"\\n\" +\n",
    "    r\"$\\boldsymbol{k_c} + \\boldsymbol{k_{hv}}\\boldsymbol{hv})$\"\n",
    ")\n",
    "\n",
    "# 遍历每种情景，绘制LOESS平滑曲线和透明散点\n",
    "for i,model in enumerate(combined_data[\"model\"].unique()):\n",
    "    model_data = combined_data[combined_data[\"model\"] == model]\n",
    "    # 使用 LOESS 进行平滑\n",
    "    loess_result = lowess(model_data[\"SOA\"], model_data[\"Temperature\"], frac=0.3)\n",
    "    # 绘制平滑曲线\n",
    "    ax2.plot(\n",
    "        loess_result[:, 0], loess_result[:, 1],\n",
    "        label=f\"{model} LOESS fit\",\n",
    "        linewidth=2.5,zorder=10,color=colors[i])\n",
    "\n",
    "\n",
    "# 用于记录每个 model 已绘制的路径数量\n",
    "plot_count = {\"Baseline\": 0, \"+1.5°C Warming\": 0, \"+2.0°C Warming\": 0, \"+3.0°C Warming\": 0}\n",
    "# 遍历每个路径数据集并绘制，确保每个 model 仅绘制 10 条路径\n",
    "for data in dataset:\n",
    "    # 确定当前路径的 model 类型\n",
    "    if data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0]:\n",
    "        model_label = \"Baseline\"\n",
    "    elif data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0] + 1.5:\n",
    "        model_label = \"+1.5°C Warming\"\n",
    "    elif data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0] + 2:\n",
    "        model_label = \"+2.0°C Warming\"\n",
    "    elif data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0] + 3:\n",
    "        model_label = \"+3.0°C Warming\"\n",
    "    else:\n",
    "        continue  # 跳过不匹配任何情景的数据\n",
    "\n",
    "    # 如果当前 model 已绘制了 10 条路径，则跳过\n",
    "    if plot_count[model_label] >= 5:\n",
    "        continue\n",
    "    # 绘制路径\n",
    "    sns.lineplot(data=data, x=\"Temperature\", y=\"SOA\", ax=ax2, color=\"grey\", alpha=0.1, linewidth=0.7, linestyle='-')\n",
    "    # 更新绘制路径计数\n",
    "    plot_count[model_label] += 1\n",
    "    \n",
    "\n",
    "# 设置标题和坐标轴标签的格式\n",
    "ax2.set_title(\"\", fontsize=5, weight='bold', pad=15)\n",
    "ax2.set_xlabel(\"Temperature (°C)\", fontsize=13, weight='bold')\n",
    "ax2.set_ylabel(r\"Average SOA ($\\boldsymbol{μg/m^3}$)\", fontsize=13, weight='bold')\n",
    "# 设置网格样式\n",
    "ax2.grid(True, linestyle='--', linewidth=0.7, alpha=0.6)\n",
    "# 优化刻度标签的样式\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax2.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.2f}'))  # Y轴格式化显示两位小数\n",
    "ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.2f}'))  # Y轴格式化显示两位小数\n",
    "# 计算 SOA 的均值和标准差\n",
    "mean_soa = dataall[\"SOA\"].mean()\n",
    "std_soa = dataall[\"SOA\"].std()\n",
    "# 绘制均值线\n",
    "ax2.axhline(y=mean_soa, color='#63E398', linestyle='--', linewidth=2, label=\"Mean SOA\")\n",
    "# 绘制正负 2 个标准差\n",
    "ax2.axhline(y=mean_soa + 1 * std_soa, color='#B1CE46', linestyle='--', linewidth=2, label=\"Mean + 1 Std Dev\")\n",
    "ax2.axhline(y=mean_soa + 2 * std_soa, color='#F1D77E', linestyle='--', linewidth=2, label=\"Mean + 2 Std Dev\")\n",
    "ax2.text(0.14, 0.93, f'Model\\nR² = {modelall.rsquared:.3f}\\n'+model_label_tex, transform=ax2.transAxes, fontsize=11, color='black', fontweight='bold', verticalalignment='top')\n",
    "ax2.legend_.remove()  \n",
    "\n",
    "\n",
    "\n",
    "#第三张图\n",
    "# 用于记录每个 model 已绘制的路径数量\n",
    "plot_count = {\"Baseline\": 0, \"+1.5°C Warming\": 0, \"+2.0°C Warming\": 0, \"+3.0°C Warming\": 0}\n",
    "# 遍历每个路径数据集并绘制，确保每个 model 仅绘制 10 条路径\n",
    "for data in dataset:\n",
    "    # 确定当前路径的 model 类型\n",
    "    if data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0]:\n",
    "        model_label = \"Baseline\"\n",
    "    elif data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0] + 1.5:\n",
    "        model_label = \"+1.5°C Warming\"\n",
    "    elif data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0] + 2:\n",
    "        model_label = \"+2.0°C Warming\"\n",
    "    elif data[\"Temperature\"].iloc[0] == dataj[\"T\"].iloc[0] + 3:\n",
    "        model_label = \"+3.0°C Warming\"\n",
    "    else:\n",
    "        continue  # 跳过不匹配任何情景的数据\n",
    "\n",
    "    # 如果当前 model 已绘制了 10 条路径，则跳过\n",
    "    if plot_count[model_label] >= 10:\n",
    "        continue\n",
    "\n",
    "    # 绘制路径\n",
    "    sns.lineplot(data=data, x=\"Time\", y=\"SOA\", ax=ax3, color=\"grey\", alpha=0.3, linewidth=0.7, linestyle='-')\n",
    "\n",
    "    # 更新绘制路径计数\n",
    "    plot_count[model_label] += 1\n",
    "# # 绘制每个情景的均值曲线\n",
    "sns.lineplot(data=combined_data, x=\"Time\", y=\"SOA\", hue=\"model\", ax=ax3, linewidth=2, palette=colors, marker=None)\n",
    "# 用于存储注释的文本对象列表\n",
    "texts = []\n",
    "# 计算并标注每个情景的均值超标和总体超标比例\n",
    "for i,model in enumerate(combined_data[\"model\"].unique()):\n",
    "    model_data = combined_data[combined_data[\"model\"] == model]\n",
    "    # 获取每个情景的中心位置\n",
    "    center_time = model_data[\"Time\"].iloc[dataset[0].shape[0] // 2]\n",
    "    center_soa = model_data[\"SOA\"].mean()\n",
    "    mean=model_data[\"SOA\"].mean()\n",
    "    std=model_data[\"SOA\"].std()\n",
    "    text = ax3.text(\n",
    "    center_time, center_soa,\n",
    "    f\"{model}\\nMean={mean:.2f}\\nStd={std:.2f}\",\n",
    "    ha='center', fontsize=12,color='black'\n",
    ")\n",
    "    texts.append(text)\n",
    "    # 添加白色描边效果\n",
    "    for text in texts:\n",
    "        text.set_path_effects([\n",
    "            path_effects.Stroke(linewidth=1.5, foreground=\"white\"),\n",
    "            path_effects.Normal()\n",
    "        ])\n",
    "# 使用 adjust_text 避免文字重叠\n",
    "adjust_text(\n",
    "    texts,\n",
    "    ax=ax3,\n",
    "    arrowprops=dict(arrowstyle=\"-|>\", color='black', zorder=10),  # 设置箭头的 zorder\n",
    ")\n",
    "# 计算 SOA 的均值和标准差\n",
    "mean_soa = dataall[\"SOA\"].mean()\n",
    "std_soa = dataall[\"SOA\"].std()\n",
    "# 绘制均值线\n",
    "ax3.axhline(y=mean_soa, color='#63E398', linestyle='--', linewidth=2, label=\"Mean SOA\")\n",
    "# 绘制正负 2 个标准差\n",
    "ax3.axhline(y=mean_soa + 1 * std_soa, color='#B1CE46', linestyle='--', linewidth=2, label=\"Mean + 1 Std Dev\")\n",
    "ax3.axhline(y=mean_soa + 2 * std_soa, color='#F1D77E', linestyle='--', linewidth=2, label=\"Mean + 2 Std Dev\")\n",
    "# 设置标题和标签\n",
    "ax3.set_title(\"\", fontsize=14, weight='bold')\n",
    "ax3.set_xlabel(\"\", fontsize=13, weight='bold')\n",
    "ax3.set_ylabel(r\"SOA ($\\boldsymbol{μg/m^3}$)\", fontsize=13, weight='bold')\n",
    "ax3.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "# 设置 x 轴的显示间隔为每 4 小时\n",
    "ax3.set_xticks(ax3.get_xticks()[::90])  \n",
    "# 优化标签\n",
    "ax3.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax3.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.2f}'))  # Y轴格式化显示两位小数\n",
    "ax3.tick_params(axis='x', labelrotation=45, labelsize=10)\n",
    "ax3.legend_.remove()  \n",
    "\n",
    "for ax in [ax1,ax2,ax3]:\n",
    "    for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "            label.set_fontweight('bold')\n",
    "\n",
    "\n",
    "# 自定义图例\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patches as mpatches\n",
    "# 自定义图例项\n",
    "legend_elements = [\n",
    "    mpatches.Patch(color='#464AA6', label=\"Baseline\"),\n",
    "    mpatches.Patch(color='#F2CB05', label=\"+1.5°C Warming\"),\n",
    "    mpatches.Patch(color='#F28A2E', label=\"+2.0°C Warming\"),\n",
    "    mpatches.Patch(color='#BF2633', label=\"+3.0°C Warming\"),\n",
    "    Line2D([0], [0], color='#63E398', linestyle='--', linewidth=2, label=\"Mean SOA\"),\n",
    "    Line2D([0], [0], color='#B1CE46', linestyle='--', linewidth=2, label=\"Mean + 1 Std Dev\"),\n",
    "    Line2D([0], [0], color='#F1D77E', linestyle='--', linewidth=2, label=\"Mean + 2 Std Dev\"),\n",
    "    Line2D([0], [0], color='grey', linestyle='-', linewidth=2, alpha=1, label=\"Monte Carlo\\nSimulation\")\n",
    "]\n",
    "# 在大图右侧添加图例\n",
    "fig.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10, prop={'size': 13, 'weight': 'bold'}, frameon=False)\n",
    "\n",
    "\n",
    "# 调整布局，确保美观\n",
    "fig.tight_layout()\n",
    "plt.savefig('随机过程模拟分析.svg',  bbox_inches='tight')\n",
    "plt.savefig('随机过程模拟分析.jpg',dpi=700,bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a97d5c-b526-4f36-9c44-f123e9612fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
